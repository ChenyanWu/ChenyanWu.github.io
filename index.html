<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Chenyan Wu</title>

    <meta name="author" content="Chenyan Wu">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
  </head>

  <body>
    <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Chenyan Wu
                </p>
                <p>I am currently a Research Scientist in the perception team at <a href="https://www.tusimple.com/">TuSimple</a>, focusing on object detection algorithms for self-driving trucks. In Oct. 2023, I defended my Ph.D. thesis in <a href="https://ist.psu.edu/">the College of Information Sciences & Technology</a> at <a href="https://www.psu.edu/">The Pennsylvania State University</a>, advised by <em>Prof. <a href="http://wang.ist.psu.edu/docs/home.shtml">James Z. Wang</a></em>. Before joining Penn State, I received my B.E. in Electronic Information Engineering from <a href="http://en.scgy.ustc.edu.cn/">the School of the Gifted Young</a>, <a href="http://en.ustc.edu.cn/">University of Science and Technology of China</a>. I have also had a wonderful time as an intern at Amazon Astro, Amazon Alexa, Microsoft Research Asia, and SenseTime Research.
                </p> 
                <!-- I am currently a Research Scientist at the perception team of TuSimple, focusing on object detection algorithms for self-driving trucks. In Oct. 2023, I defended my Ph.D. thesis in the College of Information Sciences & Technology at The Pennsylvania State University, advised by Prof. James Z. Wang. Before joining Penn State, I received my B.E. in Electronic Information Engineering from the School of the Gifted Young, University of Science and Technology of China. I have also had a wonderful time as an intern at Amazon Astro, Amazon Alexa, Microsoft Research Asia, and SenseTime Research. -->
                <p style="text-align:center">
                  <a href="mailto:czw390@psu.edu">Email</a> &nbsp;/&nbsp;
                  <a href="data/Chenyan_cv_updated.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=wDtB5FIAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/chenyan-wu-2a591615b/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://github.com/ChenyanWu">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:30%;max-width:30%">
                <a href="images/chenyanwu.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/chenyanwu.jpeg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in computer vision and affective computing. During my Ph.D., much of my research is about modeling and understanding human behaviors from images or videos, such as human bodily expressed emotion understand, 2D/3D human pose estimation. Representative papers are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr bgcolor="#ffffd0">
                <td style="padding:15px;width:35%;vertical-align:middle;height:160px;overflow:hidden;">
                    <img src="images/p-ieee.png" alt="" style="width:100%">
                </td>
                <td style="padding:15px;width:65%;vertical-align:middle">
                <a target="_blank" rel="noopener noreferrer" href="https://ieeexplore.ieee.org/abstract/document/10132377">
                    <span class="papertitle">Unlocking the Emotional World of Visual Media: An Overview of the Science, Research, and Impact of Understanding Emotion</span>
                </a>
                <br>
                James Z. Wang, Sicheng Zhao, <strong>Chenyan Wu*</strong>, Reginald B. Adams, Michelle G. Newman, Tal Shafir, Rachelle Tsachor
                <br>
                <em>Proceedings of the IEEE</em>, 2023 &nbsp&nbsp&nbsp(<strong>*</strong>sole student author)
                <br>
                <a target="_blank" rel="noopener noreferrer" href="https://ieeexplore.ieee.org/abstract/document/10132377">paper</a>
                /
                <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2307.13463">arXiv</a>
                <p>
                This 51-page article provides a comprehensive overview of the field of emotion analysis in visual media and discusses the latest research, challenges, and potential impact of artificial emotional intelligence on society.
                </p>
                </td>
            </tr>
            
            <tr bgcolor="#ffffd0">
              <td style="padding:15px;width:35%;vertical-align:middle;">
                  <img src="images/patterns.jpg" alt="" style="width:100%">
              </td>
              <td style="padding:15px;width:65%;vertical-align:middle">
              <a target="_blank" rel="noopener noreferrer" href="https://www.cell.com/patterns/fulltext/S2666-3899(23)00185-X">
                  <span class="papertitle">Bodily Expressed Emotion Understanding Through Integrating Laban Movement Analysis</span>
              </a>
              <br>
              <strong>Chenyan Wu</strong>, Dolzodmaa Davaasuren, Tal Shafir, Rachelle Tsachor, James Z. Wang
              <br>
              <em>Patterns, Cell Press</em>, 2023&nbsp&nbsp&nbsp(featured cover article)
              <br>
              <a target="_blank" rel="noopener noreferrer" href="https://www.cell.com/patterns/fulltext/S2666-3899(23)00185-X">paper</a>
              /
              <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2304.02187">arXiv</a>
              /
              <a target="_blank" rel="noopener noreferrer" href="https://data.mendeley.com/datasets/gbhpdkf8pg/1">data</a>
              /
              <a target="_blank" rel="noopener noreferrer" href="https://github.com/ChenyanWu/BoME">code</a>
              <p>
              </p>
              </td>
            </tr>

            <tr bgcolor="#ffffd0">
              <td style="padding:15px;width:35%;vertical-align:middle;height:160px;overflow:hidden;">
                  <img src="images/meta.png" alt="" style="width:100%">
              </td>
              <td style="padding:15px;width:65%;vertical-align:middle">
              <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2303.01630">
                  <span class="papertitle">Learning to Adapt to Online Streams with Distribution Shifts</span>
              </a>
              <br>
              <strong>Chenyan Wu</strong>, Yimu Pan, Yandong Li, James Z. Wang
              <br>
              <em>arXiv</em>, 2023 &nbsp&nbsp&nbsp(under peer review)
              <br>
              <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2303.01630">arXiv</a>
              <p>
              </p>
              </td>
            </tr>

            <tr bgcolor="#ffffd0">
              <td style="padding:15px;width:35%;vertical-align:middle;height:130px;overflow:hidden;">
                  <img src="images/mug.jpg" alt="" style="width:100%">
              </td>
              <td style="padding:15px;width:65%;vertical-align:middle">
              <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2205.12583">
                  <span class="papertitle">MUG: Multi-human Graph Network for 3D Mesh Reconstruction from 2D Pose</span>
              </a>
              <br>
              <strong>Chenyan Wu</strong>, Yandong Li, Xianfeng Tang, James Z. Wang
              <br>
              <em>arXiv</em>, 2022 &nbsp&nbsp&nbsp(under peer review)
              <br>
              <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2205.12583">arXiv</a>
              <p>
              </p>
              </td>
            </tr>

            <tr>
              <td style="padding:15px;width:35%;vertical-align:middle;height:160px;overflow:hidden;">
                  <img src="images/VOT.png" alt="" style="width:100%">
              </td>
              <td style="padding:15px;width:65%;vertical-align:middle">
              <a target="_blank" rel="noopener noreferrer" href="https://openaccess.thecvf.com/content/ICCV2021W/VOT/html/Kristan_The_Ninth_Visual_Object_Tracking_VOT2021_Challenge_Results_ICCVW_2021_paper.html">
                  <span class="papertitle">The Ninth Visual Object Tracking VOT2021 Challenge Results</span>
              </a>
              <br>
              Matej Kristan, Ji≈ô√≠ Matas, ..., <strong>Chenyan Wu</strong>, et al.
              <br>
              <em>IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)</em>, 2021
              <br>
              <a target="_blank" rel="noopener noreferrer" href="https://openaccess.thecvf.com/content/ICCV2021W/VOT/html/Kristan_The_Ninth_Visual_Object_Tracking_VOT2021_Challenge_Results_ICCVW_2021_paper.html">paper</a>
              <p>
              </p>
              </td>
            </tr>

            <tr bgcolor="#ffffd0">
              <td style="padding:15px;width:35%;vertical-align:middle;height:160px;overflow:hidden;">
                <img src="images/MEBOW1.png" alt="" style="width:100%">
                <!-- <img src="images/MEBOW2.png" alt="second-image" style="width:20%; display: inline-block;"> -->
              </td>
              <td style="padding:15px;width:65%;vertical-align:middle">
              <a target="_blank" rel="noopener noreferrer" href="https://openaccess.thecvf.com/content_CVPR_2020/html/Wu_MEBOW_Monocular_Estimation_of_Body_Orientation_in_the_Wild_CVPR_2020_paper.html">
                  <span class="papertitle">MEBOW: Monocular Estimation of Body Orientation In the Wild</span>
              </a>
              <br>
              <strong>Chenyan Wu</strong>, Yukun Chen, Jiajia Luo, Che-Chun Su, Anuja Dawane, Bikramjot Hanzra, Zhuo Deng, Bilan
              Liu, James Z. Wang, Cheng-hao Kuo
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2020
              <br>
              <a target="_blank" rel="noopener noreferrer" href="https://openaccess.thecvf.com/content_CVPR_2020/html/Wu_MEBOW_Monocular_Estimation_of_Body_Orientation_in_the_Wild_CVPR_2020_paper.html">paper</a>
              /
              <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2011.13688">arXiv</a>
              /
              <a target="_blank" rel="noopener noreferrer" href="https://chenyanwu.github.io/MEBOW">data</a>
              /
              <a target="_blank" rel="noopener noreferrer" href="https://github.com/ChenyanWu/MEBOW">code</a>
              <p>
              </p>
              </td>
            </tr>

            <tr>
              <td style="padding:15px;width:35%;vertical-align:middle;height:160px;overflow:hidden;">
                  <img src="images/cmig.png" alt="" style="width:100%">
              </td>
              <td style="padding:15px;width:65%;vertical-align:middle">
              <a target="_blank" rel="noopener noreferrer" href="https://www.sciencedirect.com/science/article/pii/S0895611120300471">
                  <span class="papertitle">AI-PLAX: AI-based Placental Assessment and Examination Using Photos</span>
              </a>
              <br>
              Yukun Chen, Zhuomin Zhang, <strong>Chenyan Wu</strong>, Dolzodmaa Davaasuren, Jeffery Goldstein, Alison Gernand, James Z. Wang
              <br>
              <em>Computerized Medical Imaging and Graphics (CMIG)</em>, 2020
              <br>
              <a target="_blank" rel="noopener noreferrer" href="https://www.sciencedirect.com/science/article/pii/S0895611120300471">paper</a>
              <p>
              </p>
              </td>
            </tr>

            <tr>
              <td style="padding:15px;width:35%;vertical-align:middle;height:160px;overflow:hidden;">
                  <img src="images/prl_2.png" alt="" style="width:100%">
              </td>
              <td style="padding:15px;width:65%;vertical-align:middle">
              <a target="_blank" rel="noopener noreferrer" href="https://www.sciencedirect.com/science/article/pii/S0167865520303780">
                  <span class="papertitle"> Multi-region Saliency-aware Learning for Cross-domain Placenta Image Segmentation</span>
              </a>
              <br>
              Zhuomin Zhang, Dolzodmaa Davaasuren, <strong>Chenyan Wu</strong>, Jeffery Goldstein, Alison Gernand, James Z. Wang
              <br>
              <em>Pattern Recognition Letters (PRL)</em>, 2020
              <br>
              <a target="_blank" rel="noopener noreferrer" href="https://www.sciencedirect.com/science/article/pii/S0167865520303780">paper</a>
              <p>
              </p>
              </td>
            </tr>

            <tr>
              <td style="padding:15px;width:35%;vertical-align:middle;height:160px;overflow:hidden;">
                  <img src="images/miccai.png" alt="" style="width:100%">
              </td>
              <td style="padding:15px;width:65%;vertical-align:middle">
              <a target="_blank" rel="noopener noreferrer" href="https://link.springer.com/chapter/10.1007/978-3-030-32239-7_54">
                  <span class="papertitle">PlacentaNet: Automatic Morphological Characterization of Placenta Photos with Deep Learning</span>
              </a>
              <br>
              Yukun Chen, <strong>Chenyan Wu</strong>, Zhuomin Zhang, Jeffery Goldstein, Alison Gernand, James Z. Wang
              <br>
              <em>Medical Image Computing and Computer Assisted Intervention (MICCAI)</em>, 2019
              <br>
              <a target="_blank" rel="noopener noreferrer" href="http://infolab.stanford.edu/~wangz/project/imsearch/MEDICAL/MICCAI19/chen2.pdf">paper</a>
              <p>
              </p>
              </td>
            </tr>

          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-bottom: 20px;"><tbody>
            <tr>
              <td style="padding:20px;width:20%;">
                <h2>Education</h2>
              </td>
            </tr>
            <tr>
              <td style="padding:0px;width:20%;text-align: left; padding-left: 20px;">
                08/2018 - Present
              </td>
              <td style="width:80%;">
                Ph.D., The Pennsylvania State University
              </td>
            </tr>
            <tr>
              <td style="padding:0px;width:20%;text-align: left; padding-left: 20px;">
                08/2014 - 06/2018
              </td>
              <td style="width:80%;">
                Bachelor, University of Science and Technology of China
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-bottom: 20px;"><tbody>
            <tr>
              <td style="padding:20px;width:20%;">
                <h2>Experiences</h2>
              </td>
            </tr>
            <tr>
              <td style="padding:0px;width:20%;text-align: left; padding-left: 20px;">
                10/2023 - Present
              </td>
              <td style="width:80%;">
                Research Scientist in TuSimple
              </td>
            </tr>
            <tr>
              <td style="padding:0px;width:20%;text-align: left; padding-left: 20px;">
                03/2021 - 09/2021
              </td>
              <td style="width:80%;">
                Research intern in Microsoft Research Asia
              </td>
            </tr>
            <tr>
              <td style="padding:0px;width:20%;text-align: left; padding-left: 20px;">
                06/2020 - 09/2020
              </td>
              <td style="width:80%;">
                Applied scientist intern in Amazon Alexa
              </td>
            </tr>
            <tr>
              <td style="padding:0px;width:20%;text-align: left; padding-left: 20px;">
                05/2019 - 08/2019
              </td>
              <td style="width:80%;">
                Applied scientist intern in Amazon Lab126 (the Astro team)
              </td>
            </tr>
            <tr>
              <td style="padding:0px;width:20%;text-align: left; padding-left: 20px;">
                03/2018 - 07/2018
              </td>
              <td style="width:80%;">
                Research intern in SenseTime Research
              </td>
            </tr>
            <tr>
              <td style="padding:0px;width:20%;text-align: left; padding-left: 20px;">
                07/2017 - 09/2017
              </td>
              <td style="width:80%;">
                Visiting scholar in University of Technology, Sydney
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-bottom: 20px;"><tbody>
            <tr>
              <td style="padding:20px;width:20%;">
                <h2>Service</h2>
              </td>
            </tr>
            <tr>
              <td style="padding:0px;width:20%;text-align: left; padding-left: 20px;">
                Conference Reviewer
              </td>
              <td style="width:80%;">
                WACV 2021, ECCV 2022, AAAI 2023, CVPR 2023, AAAI 2024
              </td>
            </tr>
            <tr>
              <td style="padding:0px;width:20%;text-align: left; padding-left: 20px;">
                Journal Reviewer
              </td>
              <td style="width:80%;">
                IEEE Transactions on Cybernetics
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Template adapted from <a href="https://github.com/jonbarron/jonbarron_website">this awesome website</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
